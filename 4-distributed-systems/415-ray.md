# Ray: A Distributed Framework for Emerging AI Applications

Link: https://arxiv.org/pdf/1712.05889
Read: August 2nd, 2024


* RL: RL deals with learning to operate continuously within an uncertain environment based on delayed and limited feedback 
  * Both requires distributed training
  * and to serve the policy in interactive close-loop and open-loop control scenarios.
* Systems requirements:
  * Support fine-grained computations (e.g. rendering actions in milliseconds)
  * Support heterogeneity in time (e.g. a simulation can be seconds or hours) and space (GPU and CPU)
  * Support dynamic execution (e.g. results of simulations or interactions with the environment can change future computations.)
* Existing systems
  * **Bulk-synchronous parallel systems**: MapReduce, Spark, Dryad
    * Do not support fine-grained simulation or policy serving
  * **Task-parallel systems**: CIEL, Dask
    * and **Streaming systems**: Naiad and Storm
    * Support simulation
    * Do not support distributed trianing and serving
  * **Distributed deep-learning frameworks**: TensorFlow and MXNet
    * Do not support simulation and serving
  * **Model-serving systems**: TensorFlow Serving and Clipper
    * Support neither training nor simulation.
* > While in principle one can stitch together multiple systems, in practice this approach is untenable due to the tight coupling of these components within applications.
* Ray:
  * A general purpose cluster-computing framework that enables simulation, training and serving.
  * An interface that can express both **task-parallel** and **actor-based** computations
  * The actor and task abstractions are on top of a single dynamic execution engine that is highly scalable and fault tolerant. 
* Support both stateless and stateful computations
  * Stateless computations can be executed on any node in the system, which makes it easy to achieve load balancing and movement of computation to data.
  * Stateful computations are a good fit for implementing parameter servers, performing repeated computation on GPU-backed data, or running third-party simulators that do not expose their state.
* Both task and actors. Differentiate from 
  * CIEL: which only provides task-parallel abstraction.
  * Orleans and Akka: which only provides actor-based abstraction.

## Programming Model

* **Task**
  * A task represents the execution of a remote function on a stateless worker.
  * When a remote function is invoked, a future representing the result of the task is returned immediately.
  * Futures can be retrieved using `ray.get()`, and passed as argument to other remote functions.
  * Futures operate on immutable objects and are stateless.
  * Tasks enable fine-grained load balancing through leveraging load-aware scheduling at task granularity
* **Actors**
  * A method execution is similar to a **task**, in that it executes remotely and returns a future, but differs in that it executes on a stateful worker. 
  * In contrast, actors provide much more efficient fine-grained updates, as these updates are performed on internal rather than external state, which typically requires serialization and deserialization. 
* **ray.get()**
  * Return the values associated with one or more futures. This is blocking.
* **ray.wait()**
  * Return the futures whose corresponding tasks have completed as soon as either k have completed or the timeout expires.
* Nested remote futures
  * Remote functions can invoke other remote functions.

## Computation Model

* Data edges capture the dependencies between data objects and tasks.
  * More precisely, if data object D is an output of task T , we add a data edge from T to D. Similarly, if D is an input to T , we add a data edge from D to T . 
* Control edges capture the computation dependencies that result from nested remote functions.
  * If task T1 invokes task T2, then we add a control edge from T1 to T2.
* Stateful edge
  * If method Mj is called right after method Mi on the same actor, then we add a stateful edge from Mi to Mj. 
  * Stateful edges help us embed actors in an otherwise stateless task graph, as they capture the implicit data dependency between successive method invocations sharing the internal state of an actor.

## Application Layer
* **Driver**
  * A process executing the user program.
* **Worker**
  * A stateless process that executes tasks (remote functions) invoked by a driver or another worker
* **Actor**
  * A stateful process that executes, when invoked, only the methods it exposes. Unlike a worker, an actor is explicitly instantiated by a worker or a driver. 

## System Layer

* **Global control store**
  * Key-value store for the control state of the system.
  * With pub-sub functionalities
  * Store fine-grained lineage information
  * Many systems store these information in a centralized controller, Ray move them off the critical path.

* **Distributed Scheduler**
  * Two-level scheduler: **global scheduler**, and **per-node local scheduler**.
  * A task created at a node is submitted to the node's local scheduler
  * If the node is overloaded, the per-node local scheduler forwards that task to the global scheduler.
  * Bottom-up scheduler: as the per-node scheduler schedules that locally first. 
  * The global scheduler considers each node’s load and task’s constraints to make scheduling decisions.

* **Distributed object store**
  * Object store is implemented with shared memory: allows zero-copy data sharing between tasks running on the same node.
  * If a task’s inputs are not local, the inputs are replicated to the local object store before execution.
  * Also, a task writes its outputs to the local object store.
  * Similar to Spark and Dryad, the object store is limited to immutable data.
  * Our object store does not support distributed objects, i.e., each object fits on a single node.

## Limitations
* Some operations might involve a lot of RPCs. e.g. the c = a + b example.
* OOM for Ray distributed object store. 