# Input/Output (I/O) and System Performance

## Buses, Controllers

General architecture:
* ![alt text](images/31-io/system-architecture.png)
* Single CPU attached to main memory with **memory bus** or interconnect
* Some devices are connected to the system via a general **I/O bus** (e.g. PCI)
  * PCIe is much faster than PCI. PCI bus uses parallel bus architecture (data is transmitted simultaneously across multiple channels). PCIe uses a serial bus architecture, with data transmitted through point-to-point connections. The number of lanes (x1, x4, x8, x16, etc.) determines the total bandwidth.
  * PCI is outdated. 
* **Peripheral bus** (e.g. USB, SCSI, SATA) connects **slow devices** to the system, including disks, mice, and keyboards
  
## Why this hierarchy? 

* The faster the bus is, the shorter it must be
    * High-performance memory bus does not have much room to plug devices into it
* Components demand high performance (e.g. graphic card) are nearer the CPU
* Low performance components are further away (e.g. keyboard, mouse)
* CPU connects to an I/O chip via Intel’s proprietary DMI (Direct Media Interface)
* Rest of the devices connect to this chip via different interconnect
    * Hard drive: via eSATA interface
    * USB connections: enable a keyboard and mouse to be attached to the computer
    * Higher performance devices can be connected to the system via PCIe (Peripheral Component Interconnect Express)
        * Network interface
        * Or higher performance storage devices (i.e. NVMe persistent storage devices)
    * ![alt text](images/31-io/modern-system-architecture.png.png)(Modern System Architecture)

* Device:
  * ![alt text](images/31-io/canonical-device.png)
  * Registers 
    * Status register: read to see current status of the device 
    * Command register: tell the device to perform a certain task
    * Data register: pass data or get data to / from the device 

## Programmed IO protocol: Basic Steps of OS of doing I/O

* Polling the device 
* Sending data down to data register 
* Writing a command to command register, let the device know that data is present and it should begin working
* Waiting until the device to finish by polling it from a loop 

Used in legacy systems or embedded systems. 

## Interrupts v.s. Polling

* Polling
    * OS check devices status with frequent polling
    * Pros: high CPU overhead
* Interrupts
    * When device finished operation, raise a hardware interrupt
    * CPU jump into the OS at predetermined **interrupt service routine (ISR)** or, **interrupt handler**
    * The handler (i.e. a piece of OS code) finishes the request and wakes the process waiting for I/O
    * Interrupts thus allow for overlap of computation and I/O, which is key for improved utilization. 
* Trade-offs
    * If device finishes quickly or in networks where there is huge stream of incoming packets
        * then interrupt overhead (context switching) is expensive, OS can even livelock, better to poll
    * Better to use a hybrid approach if speed of device unknown: polls for a while then interrupt. 
    * Using an interrupt in this case will actually slow down the system: switching to another process, handling the interrupt, and switching back to the issuing process is expensive. Thus, **if a device is fast, it may be best to poll; if it is slow, interrupts, which allow**
    * When a huge stream of incoming packets each generate an interrupt, it is possible for the OS to livelock, that is, find itself only processing interrupts and never allowing a user-level process to run and actually service the requests.

* **Coalescing**
    * A device which needs to raise an interrupt first waits before delivering interrupt to CPU
    * While waiting, other requests may soon complete
    * Multiple interrupts can be **coalesced** into a single interrupt delivery
  
## PIO v.s. DMA

* **PIO (programed I/O)**: CPU directly tells device what the data is
    * too much time moving data to and from device by hand
* Solution: **direct memory access (DMA)**
    * DMA: a very specific **device** within a system that can orchestrate transfer between devices and main memory without much CPU intervention
* To transfer data to device
    * OS program the DMA engine by telling it where data lives in memory, how much data to copy, and which device to send it to
    * OS is done with transfer and proceed with other work
    * DMA completes —> raise an interrupt, OS knows it complete


* **Explicit I/O instructions** 
    * Each device has a **port**
    * E.x. X86, `in` and `out` instructions can be used to communicate with devices
        * These are distinct instructions separate from regular load and store instructions that access memory 
        * For example, to send data to a device, the caller specifies a register with the data in it, and a specific **port** which names the device. Executing the instruction leads to the desired behavior.
    * These instructions are privileged, OS is the only entity that is able to directly communicate with them 
        * Less flexible, less portable (to different HW that does not support these special instructions)

* **Memory-mapped I/O**    
    * **H/W maps registers into address space**  
        * the hardware makes device registers available as if they were memory locations.
        * Doesn’t differentiate memory address and device address 
        * Underlying HW take care of routing instruction to the correct place (i.e. either memory or particular device) 
    * **To access register** 
        * OS issues a load (to read) or store (to write) the address 
        * Hardware then routes the load / store to the device instead of main memory 
    * Pros
        * More flexible as you can use same set of instructions, portable (use standard memory instruction)

**Both approaches are being used**
* FS
    * completely oblivious to specifics on which disk class it is using
    * simply issue R/W request to the generic block layer
* Raw interface to device
    * Enables special applications (i.e. FS checker, disk fragmentation tool) to directly R/W blocks without the FS abstraction
* Downside of this
    * Specialized device, general interface
* Device driver
    * Protocol for talking with devices
    * Write device driver for each device
    * 70% of OS code in Linux kernel

